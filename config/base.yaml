defaults:  
  - _self_  
  - override hydra/hydra_logging: disabled  
  - override hydra/job_logging: disabled  
  
hydra:  
  output_subdir: null  
  run:  
    dir: .

wandb:
  proj_name: "?"
  num_examples_reported: 100

tok_data:
  train_file: "data/?.json"
  val_file: "data/?.json"
  tokenizer_path: "tokenizer/tokenizer.json"

data:
  datapath: data
  train_file: "?.json"
  val_file: "?.json"
  test_file: "?.json"
  num_workers: 32
  split_str: "?"
  
model:
  name: "Pythia-${model.n_layer}-${model.n_head}-${model.n_embd}-?"
  batch_size: 512
  accumulate_grad_batches: 1
  block_size: 1024
  epochs: 100

  n_layer: 12
  n_head: 8
  n_embd: 256

  vocab_size: ?
  padded_vocab_size: ?
  bos_id: ?
  eos_id: ?

optim:
  lr_type: "linear" # options: linear or linear-reg, 
                    # otherwise cosine decay

eval:
  num_examples: 2048
  batch_size: 2048
  results_dir: "data/eval_results/${model.name}"

convert_hf:
  in_path: "temp/${model.name}"
  out_path: "temp/hf_${model.name}"

inference:
  modelpath: "./temp/hf_Pythia-${model.n_layer}-${model.n_head}-${model.n_embd}-KI"
  datapath: ${data.datapath}/test_set/
  batch_size: 2048